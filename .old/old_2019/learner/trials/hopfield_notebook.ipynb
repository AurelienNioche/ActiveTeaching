{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "def plot_currents():\n",
    "\n",
    "    data = currents\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(data)\n",
    "    ax.set_aspect(\"auto\")\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    ax.set_title(\"Network currents history\")\n",
    "    ax.set_xlabel(\"Neuron\")\n",
    "    ax.set_ylabel(\"Iteration\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_weights():\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.contourf(weights)\n",
    "    ax.set_aspect(\"auto\")\n",
    "\n",
    "    ax.set_title(\"Weights matrix\")\n",
    "    ax.set_xlabel(\"Neuron $i$\")\n",
    "    ax.set_ylabel(\"Neuron $j$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mean_weights(network):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.plot(weights_mean)\n",
    "    # ax.set_aspect(\"auto\")\n",
    "\n",
    "    ax.set_title(\"Weights learning rule\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Difference of means\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_p_recall(network):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.plot(p_recall_history)\n",
    "\n",
    "    ax.set_title(\"Probability of recall\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Pattern match\")\n",
    "    ax.set_ylim((-0.1, 1.1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_energy(network):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    x = np.arange(0, num_neurons, 1)\n",
    "    y = np.arange(0, num_neurons, 1)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    z = np.copy(network.weights)\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(num_neurons):\n",
    "            z[i, j] *= currents[-1, j]\n",
    "\n",
    "    surf = ax.plot_surface(x, y, z, alpha=0.9, cmap=\"viridis\",\n",
    "                           antialiased=True)\n",
    "\n",
    "    ax.set_title(\"Energy landscape\")\n",
    "    ax.set_xlabel(\"Neuron $i$\")\n",
    "    ax.set_ylabel(\"Neuron $j$\")\n",
    "    ax.set_zlabel(\"Energy\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 299/1000 [00:00<00:00, 2987.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patterns:\n",
      " [[0 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 915.89it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -2 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-39dcb8e71b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-39dcb8e71b69>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(force, next_theoretical_weights)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mcalculate_next_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_theoretical_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mupdate_all_neurons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mplot_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mcalculate_next_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-39dcb8e71b69>\u001b[0m in \u001b[0;36mupdate_all_neurons\u001b[0;34m(currents)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdate_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0m_update_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# self.currents_history = np.vstack((self.currents_history,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-39dcb8e71b69>\u001b[0m in \u001b[0;36m_update_current\u001b[0;34m(neuron)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mneuron\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     currents[-1, neuron] = _activation_function(dot_product\n",
      "\u001b[0;31mIndexError\u001b[0m: index -2 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "num_neurons = 1000\n",
    "p = 16\n",
    "f = 0.1\n",
    "inverted_fraction = 0.3\n",
    "noise_variance = 65\n",
    "first_p = 0\n",
    "learning_rate = 0.3\n",
    "forgetting_rate=0.1\n",
    "\n",
    "assert learning_rate <= 1\n",
    "assert forgetting_rate <= 1\n",
    "\n",
    "weights = np.zeros((num_neurons, num_neurons))\n",
    "\n",
    "next_theoretical_weights = np.zeros_like(weights)\n",
    "\n",
    "next_weights = np.zeros_like(weights)\n",
    "weights_mean = []\n",
    "\n",
    "p_recall_history = []\n",
    "\n",
    "active_fraction = f\n",
    "\n",
    "initial_currents = np.zeros(num_neurons)\n",
    "\n",
    "patterns = \\\n",
    "            np.random.choice([0, 1], p=[1 - f, f],\n",
    "                             size=(p, num_neurons))\n",
    "print(\"\\nPatterns:\\n\", patterns)\n",
    "\n",
    "currents = np.zeros((1, num_neurons), dtype=int)\n",
    "patterns_evolution = None\n",
    "\n",
    "question_pattern = np.zeros(num_neurons)\n",
    "\n",
    "    # def present_pattern(self, item):\n",
    "    #     kanji = item[\"kanji\"]\n",
    "    #     meaning = item[\"meaning\"]\n",
    "    #\n",
    "    #     self.patterns.append(np.concatenate((kanji, meaning), axis=None))\n",
    "\n",
    "def binarize_item(item):\n",
    "    \"\"\"\n",
    "    Item number to binary and append zeros according to network size.\n",
    "\n",
    "    :param item: int item index\n",
    "    :return: bin_item binary vector\n",
    "    \"\"\"\n",
    "    question_array = np.array([item])\n",
    "    bin_item = ((question_array[:, None]\n",
    "                     & (1 << np.arange(8))) > 0).astype(int)\n",
    "    bin_item = np.append(bin_item, np.zeros(self.num_neurons\n",
    "                                            - bin_item.size))\n",
    "\n",
    "    print(\"Item given as pattern:\", bin_item)\n",
    "    return bin_item\n",
    "\n",
    "\n",
    "def distort_pattern(pattern, proportion):\n",
    "    \"\"\"\n",
    "    Inverts the array in random positions proportional to array size.\n",
    "\n",
    "    :param pattern: array-like binary vector to distort\n",
    "    :param proportion: float 0 to 1, 1 being full array inversion\n",
    "\n",
    "    :return pattern: array-like binary vector with inverted elements\n",
    "    \"\"\"\n",
    "\n",
    "    num_inversions = int(pattern.size * proportion)\n",
    "    assert proportion != 1\n",
    "    idx_reassignment = np.random.choice(pattern.size, num_inversions,\n",
    "                                        replace=False)\n",
    "    pattern[idx_reassignment] = np.invert(pattern[idx_reassignment] - 2)\n",
    "    print(\"\\nDistorted pattern (i.e. initial currents)...\\n\", pattern,\n",
    "          \"\\n ...in positions\\n\", idx_reassignment)\n",
    "    return pattern\n",
    "\n",
    "def _initialize_currents():\n",
    "    \"\"\"Initial currents are set to the first distorted pattern.\"\"\"\n",
    "\n",
    "    currents = np.copy(distort_pattern(\n",
    "        patterns[self.first_p],\n",
    "        inverted_fraction)\n",
    "    )\n",
    "\n",
    "    # print(\"\\nInitial currents:\\n\", self.currents)\n",
    "\n",
    "def calculate_next_weights(pattern, next_theoretical_weights=next_theoretical_weights):\n",
    "    \"\"\"\n",
    "    Calculate the weights after the presentation of a new pattern but does\n",
    "    not change the current weights of the network\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(num_neurons)):\n",
    "        for j in range(num_neurons):\n",
    "            if j >= i:\n",
    "                break\n",
    "\n",
    "            next_theoretical_weights[i, j] += (2 * pattern[i] - 1) \\\n",
    "                                                   * (2 * pattern[j] - 1) \\\n",
    "\n",
    "    next_theoretical_weights += next_theoretical_weights.T\n",
    "\n",
    "def update_weights(weights):\n",
    "    weights += weights\n",
    "\n",
    "    def compute_weights_all_patterns():\n",
    "        print(f\"\\n...Computing weights for all patterns...\\n\")\n",
    "\n",
    "        for p in tqdm(range(len(patterns))):\n",
    "            calculate_next_weights(patterns[p])\n",
    "            update_weights(next_theoretical_weights)\n",
    "            print(next_theoretical_weights)\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "\n",
    "def _activation_function(x):\n",
    "    \"\"\"Heaviside\"\"\"\n",
    "    return int(x >= 0)\n",
    "\n",
    "def noise():\n",
    "    # Amplitude-modulated Gaussian noise\n",
    "    return np.random.normal(loc=0, scale=noise_variance**0.5) * 0.05\n",
    "\n",
    "def _update_current(neuron):\n",
    "    \"\"\"\n",
    "    If you are updating one node of a Hopfield network, then the values of\n",
    "    all the other nodes are input values, and the weights from those nodes\n",
    "    to the updated node as the weights.\n",
    "\n",
    "    In other words, first you do a weighted sum of the inputs from the\n",
    "    other nodes, then if that value is greater than or equal to 0, you\n",
    "    output 1. Otherwise, you output 0\n",
    "\n",
    "    :param neuron: int neuron number\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(weights[neuron], currents[-2])\n",
    "\n",
    "    currents[-1, neuron] = _activation_function(dot_product\n",
    "                                                          + noise())\n",
    "\n",
    "def update_all_neurons(currents=currents):\n",
    "    \"\"\"\n",
    "    Neurons are updated update in random order as described by Hopfield.\n",
    "    The full network should be updated before the same node gets updated\n",
    "    again.\n",
    "    \"\"\"\n",
    "    # self.last_currents = self.currents\n",
    "\n",
    "    values = np.arange(0, num_neurons, 1)\n",
    "    update_order = np.random.choice(values,\n",
    "                                    num_neurons,\n",
    "                                    replace=False)\n",
    "\n",
    "    currents = np.vstack((currents, np.zeros(num_neurons)))\n",
    "\n",
    "    for i in update_order:\n",
    "        _update_current(i)\n",
    "\n",
    "    # self.currents_history = np.vstack((self.currents_history,\n",
    "    #                                    self.currents))\n",
    "\n",
    "def _update_current_learning(neuron):\n",
    "    \"\"\"\n",
    "    If you are updating one node of a Hopfield network, then the values of\n",
    "    all the other nodes are input values, and the weights from those nodes\n",
    "    to the updated node as the weights.\n",
    "\n",
    "    In other words, first you do a weighted sum of the inputs from the\n",
    "    other nodes, then if that value is greater than or equal to 0, you\n",
    "    output 1. Otherwise, you output 0\n",
    "\n",
    "    :param neuron: int neuron number\n",
    "    \"\"\"\n",
    "    random_currents = \\\n",
    "        np.random.choice([0, 1], p=[1 - self.f, self.f],\n",
    "                         size=num_neurons)\n",
    "    dot_product = np.dot(weights[neuron], random_currents)\n",
    "\n",
    "    self.currents[-1, neuron] = _activation_function(dot_product\n",
    "                                                          + noise())\n",
    "\n",
    "def update_all_neurons_learning():\n",
    "    \"\"\"\n",
    "    Neurons are updated update in random order as described by Hopfield.\n",
    "    The full network should be updated before the same node gets updated\n",
    "    again.\n",
    "    \"\"\"\n",
    "    # self.last_currents = self.currents\n",
    "\n",
    "    values = np.arange(0, num_neurons, 1)\n",
    "    neuron_update_order = np.random.choice(values,\n",
    "                                           num_neurons,\n",
    "                                           replace=False)\n",
    "\n",
    "    currents = np.vstack((currents, np.zeros(num_neurons)))\n",
    "\n",
    "    for neuron in neuron_update_order:\n",
    "        self._update_current(neuron)\n",
    "\n",
    "    # self.currents_history = np.vstack((self.currents_history,\n",
    "    #                                    self.currents))\n",
    "\n",
    "def _compute_patterns_evolution():\n",
    "\n",
    "    for p in range(p):\n",
    "        similarity = np.sum(currents[-1] == patterns[p])\n",
    "        self.patterns_evolution = \\\n",
    "            np.vstack((patterns_evolution, similarity))\n",
    "\n",
    "    patterns_evolution = patterns_evolution.T\n",
    "    patterns_evolution = patterns_evolution[0, 1:]\n",
    "\n",
    "def _find_attractor():\n",
    "    \"\"\"\n",
    "    If an update does not change any of the node values, the network\n",
    "    rests at an attractor and updating stops.\n",
    "    \"\"\"\n",
    "    tot = 1\n",
    "\n",
    "    while (currents[-1] != currents[-2]).all() or tot < 2:  # np.sum(self.currents - self.last_currents) != 0:\n",
    "        self.update_all_neurons()\n",
    "        self._compute_patterns_evolution()\n",
    "        tot += 1\n",
    "        print(f\"\\nUpdate {tot} finished.\\n\")\n",
    "\n",
    "    attractor = np.int_(np.copy(currents[-1]))\n",
    "\n",
    "    print(f\"\\nFinished as attractor {attractor} after {tot} \"\n",
    "          f\"node value updates.\\n\")\n",
    "\n",
    "def simulate():\n",
    "    # assert patterns\n",
    "    # assert num_neurons == patterns[0].size\n",
    "\n",
    "    # _initialize()\n",
    "    compute_weights_all_patterns()\n",
    "    _initialize_currents()\n",
    "    update_all_neurons()\n",
    "    _find_attractor()\n",
    "\n",
    "def learn(item=None, time=None):\n",
    "    \"\"\"\n",
    "    The normalized difference of means calculated at every time step gives\n",
    "    a logarithmic emergent behavior as the weights get closer to the\n",
    "    theoretical ones.\n",
    "\n",
    "    :param item:\n",
    "    :param time:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    next_weights = (next_theoretical_weights - weights) \\\n",
    "        * learning_rate\n",
    "    # print(self.next_weights)\n",
    "\n",
    "    update_weights(next_weights)\n",
    "\n",
    "    weights_mean.append(-np.mean(next_theoretical_weights)\n",
    "                             + np.mean(weights))\n",
    "\n",
    "    # plot.attractor_networks.plot_weights(self)\n",
    "    # pass\n",
    "\n",
    "def fully_learn(self):\n",
    "    # tot = 1\n",
    "    #\n",
    "    # while (self.weights[-1] != self.next_theoretical_weights).all():\n",
    "    #     self.learn()\n",
    "    #     tot += 1\n",
    "    #\n",
    "    # print(f\"\\nFinished learning after {tot} \"\n",
    "    #       f\"node weight updates.\\n\")\n",
    "    pass\n",
    "\n",
    "def forget():\n",
    "    next_weights = (weights + noise() * 10000000) \\\n",
    "        * forgetting_rate\n",
    "\n",
    "    update_weights(next_weights)\n",
    "\n",
    "    weights_mean.append(-np.mean(next_theoretical_weights)\n",
    "                             + np.mean(weights))\n",
    "\n",
    "def simulate_learning(iterations, recalled_pattern):\n",
    "\n",
    "    if p == 1:\n",
    "        calculate_next_weights(patterns[first_p])\n",
    "        update_all_neurons()\n",
    "    else:\n",
    "        # for p in range(self.p - 2):\n",
    "        for p in range(len(patterns - 1)):\n",
    "            calculate_next_weights(patterns[p])\n",
    "            update_weights(next_theoretical_weights)\n",
    "\n",
    "        # self.currents = np.vstack((self.currents,\n",
    "                                   # np.zeros(self.num_neurons)))\n",
    "        calculate_next_weights(patterns[self.p - 1])\n",
    "        update_all_neurons()\n",
    "    # self.update_all_neurons()\n",
    "\n",
    "    p_recall(n_pattern=recalled_pattern)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        learn()\n",
    "        update_all_neurons()\n",
    "        p_recall(n_pattern=recalled_pattern)\n",
    "\n",
    "def p_recall(item=None, n_pattern=None, time=None, verbose=False):\n",
    "    \"\"\"\n",
    "    After choosing, compare the chosen pattern with the correct pattern\n",
    "    to retrieve the probability of recall.\n",
    "    \"\"\"\n",
    "    assert item is not None or n_pattern is not None\n",
    "    if item is not None:\n",
    "        bin_item = binarize_item(item)\n",
    "    if n_pattern is not None:\n",
    "        bin_item = patterns[n_pattern]\n",
    "\n",
    "    # self.currents = np.vstack((self.currents, bin_item))\n",
    "    # self.update_all_neurons()\n",
    "\n",
    "    match = np.sum(currents[-1] == bin_item)\n",
    "    p_r = match / num_neurons\n",
    "    p_recall_history.append(p_r)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nCurrent after item presentation and one update:\\n\",\n",
    "              currents[-1])\n",
    "        print(\"\\nProbability of recall of the item: \", p_r)\n",
    "\n",
    "    return p_r\n",
    "\n",
    "# End of original class methods #\n",
    "\n",
    "\n",
    "def main(force=False, next_theoretical_weights=next_theoretical_weights):\n",
    "\n",
    "    bkp_file = f\"bkp/hopfield.p\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(bkp_file), exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(bkp_file) or force:\n",
    "\n",
    "        np.random.seed(123)\n",
    "\n",
    "        # flower = {\"kanji\": np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "        #           \"meaning\": np.array([1, 1, 1, 0, 0, 0, 0, 0, 0, 1])}\n",
    "        #\n",
    "        # leg = {\"kanji\": np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
    "        #        \"meaning\": np.array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1])}\n",
    "        #\n",
    "        # eye = {\"kanji\": np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
    "        #        \"meaning\": np.array([0, 0, 0, 0, 1, 0, 1, 1, 1, 1])}\n",
    "\n",
    "\n",
    "        num_neurons=80,\n",
    "        f=0.55,\n",
    "        p=2,\n",
    "        first_p=0,\n",
    "        inverted_fraction=0.5,\n",
    "        learning_rate=0.1,\n",
    "        forgetting_rate=0.1\n",
    "\n",
    "\n",
    "        # network.present_pattern(flower)\n",
    "        # network.present_pattern(leg)\n",
    "        # network.present_pattern(eye)\n",
    "\n",
    "        # # learning loop\n",
    "        # network.calculate_next_weights(network.patterns[0])\n",
    "        # network.update_weights(network.next_theoretical_weights)\n",
    "        # network.calculate_next_weights(network.patterns[0])\n",
    "        # network.update_all_neurons()\n",
    "        #\n",
    "        # network.p_recall(n_pattern=0)\n",
    "        #\n",
    "        # for i in range(20):\n",
    "        #     network.learn()\n",
    "        #     network.update_all_neurons_learning()\n",
    "        #     network.p_recall(n_pattern=0)\n",
    "\n",
    "        calculate_next_weights(patterns[0])\n",
    "        update_weights(next_theoretical_weights)\n",
    "        update_all_neurons()\n",
    "        plot_weights()\n",
    "        calculate_next_weights(patterns[1])\n",
    "        p_recall(n_pattern=1)\n",
    "\n",
    "        print(next_theoretical_weights)\n",
    "\n",
    "        for i in range(1750):\n",
    "            learn()\n",
    "            update_all_neurons_learning()\n",
    "            p_recall(n_pattern=1)\n",
    "\n",
    "        plot_weights(network)\n",
    "\n",
    "        # network.simulate_learning(iterations=100, recalled_pattern=2)\n",
    "\n",
    "        weights = np.zeros_like(next_theoretical_weights)\n",
    "        next_theoretical_weights = np.zeros_like(weights)\n",
    "        print(weights)\n",
    "        compute_weights_all_patterns()\n",
    "        plot_weights()\n",
    "\n",
    "\n",
    "        pickle.dump(open(bkp_file, \"wb\"))\n",
    "    else:\n",
    "        print(\"Loading from pickle file...\")\n",
    "        network = pickle.load(open(bkp_file, \"rb\"))\n",
    "\n",
    "    plot_mean_weights()\n",
    "    plot_energy()\n",
    "    plot_p_recall()\n",
    "    plot_currents()\n",
    "    # plot_weights()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
