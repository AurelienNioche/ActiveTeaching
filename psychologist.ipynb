{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "EPS = np.finfo(np.float).eps\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grid_param(grid_size, bounds):\n",
    "\n",
    "    return np.asarray(list(\n",
    "        product(*[\n",
    "            np.linspace(*bounds[key], grid_size) \n",
    "            for key in sorted(bounds)])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_lik(n_item, n_param_set, grid_param, learner):\n",
    "    \n",
    "    log_lik = np.zeros((n_item, n_param_set, 2))\n",
    "    for i in range(self.n_item):\n",
    "        log_lik[i, :, :] = np.log(learner.p_grid(grid_param, i) + EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(ll, lp):\n",
    "\n",
    "    lp_reshaped = lp.reshape((1, len(lp), 1))\n",
    "\n",
    "    # ll => likelihood\n",
    "    # shape (n_item, n_param_set, num_responses, )\n",
    "\n",
    "    # Calculate the marginal log likelihood.\n",
    "    # shape (n_item, num_responses, )\n",
    "    mll = logsumexp(ll + lp_reshaped, axis=1)\n",
    "\n",
    "    # Calculate the marginal entropy and conditional entropy.\n",
    "    # shape (n_item,)\n",
    "    ent_mrg = - np.sum(np.exp(mll) * mll, -1)\n",
    "\n",
    "    # Compute entropy obs -------------------------\n",
    "\n",
    "    # shape (n_item, n_param_set, num_responses, )\n",
    "    # shape (n_item, n_param_set, )\n",
    "    ent_obs = - np.multiply(np.exp(ll), ll).sum(-1)\n",
    "\n",
    "    # Compute conditional entropy -----------------\n",
    "\n",
    "    # shape (n_item,)\n",
    "    ent_cond = np.sum(np.exp(lp) * ent_obs, axis=1)\n",
    "\n",
    "    # Calculate the mutual information. -----------\n",
    "    # shape (n_item,)\n",
    "    mutual_info = ent_mrg - ent_cond\n",
    "\n",
    "    return mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mutual_info(learner):\n",
    "\n",
    "        n_seen = int(np.sum(learner.seen))\n",
    "        n_not_seen = self.n_item - n_seen\n",
    "\n",
    "        seen = np.zeros(self.n_item, dtype=bool)\n",
    "        seen[:] = self.learner.seen\n",
    "\n",
    "        not_seen = np.zeros(self.n_item, dtype=bool)\n",
    "        not_seen[:] = np.logical_not(self.learner.seen)\n",
    "\n",
    "        if n_seen == 0:\n",
    "            self._compute_log_lik()\n",
    "            return\n",
    "\n",
    "        n_sample = min(n_seen+1, self.n_item)\n",
    "\n",
    "        log_lik = np.zeros((n_sample, self.n_param_set, 2))\n",
    "\n",
    "        items_seen = self.items[self.learner.seen]\n",
    "\n",
    "        if n_not_seen > 0:\n",
    "            item_not_seen = self.items[not_seen][0]\n",
    "            item_sample = list(items_seen) + [item_not_seen, ]\n",
    "        else:\n",
    "            item_sample = items_seen\n",
    "\n",
    "        for i, item in enumerate(item_sample):\n",
    "            log_lik[i, :, :] = self._log_p(item)\n",
    "\n",
    "        self.log_lik[seen] = log_lik[:n_seen]\n",
    "        if n_not_seen:\n",
    "            self.log_lik[not_seen] = log_lik[-1]\n",
    "\n",
    "        mutual_info = self._mutual_info(\n",
    "            self.log_lik,\n",
    "            self.log_post)\n",
    "\n",
    "        ll_after_pres = np.zeros((n_sample, self.n_param_set, 2))\n",
    "\n",
    "        for i, item in enumerate(item_sample):\n",
    "\n",
    "            for response in (0, 1):\n",
    "                self.learner.update(item=item, response=response)\n",
    "\n",
    "                ll_after_pres[i] += self._log_p(item)\n",
    "\n",
    "                # Unlearn item\n",
    "                self.learner.cancel_update()\n",
    "\n",
    "        ll_without_pres = np.zeros((n_sample, self.n_param_set, 2))\n",
    "\n",
    "        # Go to the future\n",
    "        self.learner.update(item=None, response=None)\n",
    "\n",
    "        for i, item in enumerate(item_sample):\n",
    "            ll_without_pres[i] = self._log_p(item)\n",
    "\n",
    "        # Cancel\n",
    "        self.learner.cancel_update()\n",
    "\n",
    "        self.ll_after_pres_full[seen] = ll_after_pres[:n_seen]\n",
    "\n",
    "        self.ll_without_pres_full[seen] = ll_without_pres[:n_seen]\n",
    "\n",
    "        if n_not_seen:\n",
    "            self.ll_after_pres_full[not_seen] = ll_after_pres[-1]\n",
    "            self.ll_without_pres_full[not_seen] = ll_without_pres[-1]\n",
    "\n",
    "        max_info_next_time_step = np.zeros(self.n_item)\n",
    "\n",
    "        with Pool() as pool:\n",
    "            max_info_next_time_step[:] = \\\n",
    "                pool.map(self.compute_max_info_time_step, self.items)\n",
    "\n",
    "        self.mutual_info[:] = mutual_info + max_info_next_time_step\n",
    "\n",
    "    def compute_max_info_time_step(self, i):\n",
    "\n",
    "        ll_t_plus_one = np.zeros((self.n_item, self.n_param_set, 2))\n",
    "\n",
    "        ll_t_plus_one[:] = self.ll_without_pres_full[:]\n",
    "        ll_t_plus_one[i] = self.ll_after_pres_full[i]\n",
    "\n",
    "        mutual_info_t_plus_one_given_i = \\\n",
    "            self._mutual_info(ll_t_plus_one,\n",
    "                              self.log_post)\n",
    "\n",
    "        return np.max(mutual_info_t_plus_one_given_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post(log_post) -> np.ndarray:\n",
    "    \"\"\"Posterior distributions of joint parameter space\"\"\"\n",
    "    return np.exp(log_post)\n",
    "\n",
    "\n",
    "def post_mean(post, grid_param) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A vector of estimated means for the posterior distribution.\n",
    "    Its length is ``n_param_set``.\n",
    "    \"\"\"\n",
    "    return np.dot(post, grid_param)\n",
    "\n",
    "\n",
    "def post_cov(grid_param, post_mean, post) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    An estimated covariance matrix for the posterior distribution.\n",
    "    Its shape is ``(num_grids, n_param_set)``.\n",
    "    \"\"\"\n",
    "    # shape: (N_grids, N_param)\n",
    "    d = grid_param - post_mean\n",
    "    return np.dot(d.T, d * post.reshape(-1, 1))\n",
    "\n",
    "\n",
    "def post_sd(post_cov) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A vector of estimated standard deviations for the posterior\n",
    "    distribution. Its length is ``n_param_set``.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.diag(post_cov))\n",
    "\n",
    "def update(log_post, log_lik, item, response):\n",
    "    r\"\"\"\n",
    "    Update the posterior :math:`p(\\theta | y_\\text{obs}(t), d^*)` for\n",
    "    all discretized values of :math:`\\theta`.\n",
    "\n",
    "    .. math::\n",
    "        p(\\theta | y_\\text{obs}(t), d^*) =\n",
    "            \\frac{ p( y_\\text{obs}(t) | \\theta, d^*) p_t(\\theta) }\n",
    "                { p( y_\\text{obs}(t) | d^* ) }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    item\n",
    "        integer (0...N-1)\n",
    "    response\n",
    "        0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    log_post += log_lik[item, :, int(response)].flatten()\n",
    "    log_post -= logsumexp(log_post)\n",
    "\n",
    "    return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_grid(grid_param, i, delta, n_pres_minus_one):\n",
    "    \n",
    "        def p_grid(self, grid_param, i):\n",
    "\n",
    "        n_param_set = len(grid_param)\n",
    "        p = np.zeros((n_param_set, 2))\n",
    "\n",
    "        i_has_been_seen = self.seen[i] == 1\n",
    "        if i_has_been_seen:\n",
    "\n",
    "            fr = grid_param[:, 0] \\\n",
    "                * (1 - grid_param[:, 1]) ** self.n_pres_minus_one[i]\n",
    "            assert np.all(fr >= 0), f\"{fr[fr<=0][0]}\"\n",
    "            p[:, 1] = np.exp(\n",
    "                - fr\n",
    "                * self.delta[i])\n",
    "\n",
    "        p[:, 0] = 1 - p[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-794cf4759d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m                        fig_folder=FIG_FOLDER)\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-794cf4759d66>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mn_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mn_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task_param' is not defined"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "\n",
    "    n_trial = 100\n",
    "    n_item = 10\n",
    "    \n",
    "    bounds = {\n",
    "        'alpha': (0.00, 1.0),\n",
    "        'beta': (0.00, 1.0),\n",
    "    }\n",
    "\n",
    "    param = sorted(bounds.keys())\n",
    "\n",
    "    post_means = {pr: np.zeros(n_trial) for pr in param}\n",
    "    post_sds = {pr: np.zeros(n_trial) for pr in param}\n",
    "\n",
    "    p = np.zeros((n_item, n_trial))\n",
    "    fr = np.zeros((n_item, n_trial))\n",
    "    p_seen = []\n",
    "    fr_seen = []\n",
    "\n",
    "    hist_item = np.zeros(n_trial, dtype=int)\n",
    "    hist_success = np.zeros(n_trial, dtype=bool)\n",
    "\n",
    "    n_seen = np.zeros(n_trial, dtype=int)\n",
    "\n",
    "    # Create learner and engine\n",
    "    learner = learner_model(param=learner_param, task_param=task_param)\n",
    "    engine = engine_model(\n",
    "        teacher_model=teacher_model,\n",
    "        teacher_param=teacher_param,\n",
    "        learner_model=learner_model,\n",
    "        task_param=task_param,\n",
    "        **engine_param\n",
    "    )\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for t in tqdm(range(n_trial)):\n",
    "\n",
    "        # Compute an optimal design for the current trial\n",
    "        item = engine.get_item()\n",
    "\n",
    "        # Get a response using the optimal design\n",
    "        p_recall = learner.p(item=item)\n",
    "\n",
    "        response = p_recall > np.random.random()\n",
    "\n",
    "        # Update the engine\n",
    "        engine.update(item=item, response=response)\n",
    "\n",
    "        # Make the user learn\n",
    "        learner.update(item=item, response=response)\n",
    "\n",
    "        # Backup the mean/std of post dist\n",
    "        for i, pr in enumerate(param):\n",
    "            post_means[pr][t] = engine.post_mean[i]\n",
    "            post_sds[pr][t] = engine.post_sd[i]\n",
    "\n",
    "        # Backup prob recall / forgetting rates\n",
    "        fr[:, t], p[:, t] = \\\n",
    "            learner.forgetting_rate_and_p_all()\n",
    "\n",
    "        fr_seen_t, p_seen_t = \\\n",
    "            learner.forgetting_rate_and_p_seen()\n",
    "\n",
    "        fr_seen.append(fr_seen_t)\n",
    "        p_seen.append(p_seen_t)\n",
    "\n",
    "        # Backup history\n",
    "        n_seen[t] = np.sum(learner.seen)\n",
    "\n",
    "        hist_item[t] = item\n",
    "        hist_success[t] = response\n",
    "        \n",
    "        fig_parameter_recovery(param=param, design_types=labels,\n",
    "                       post_means=data[POST_MEAN], post_sds=data[POST_SD],\n",
    "                       true_param=learner_param,\n",
    "                       num_trial=task_param['n_trial'],\n",
    "                       fig_name=fig_name,\n",
    "                       fig_folder=FIG_FOLDER)\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "\n",
    "    def __init__(self, learner_model, task_param, teacher_model, teacher_param,\n",
    "                 grid_size=5, true_param=None):\n",
    "\n",
    "        self.learner_model = learner_model\n",
    "\n",
    "        self.grid_param = self._compute_grid_param(grid_size)\n",
    "        self.n_param_set = len(self.grid_param)\n",
    "\n",
    "        self.n_item = task_param['n_item']\n",
    "        self.items = np.arange(self.n_item)\n",
    "\n",
    "        self.log_lik = np.zeros((self.n_item,\n",
    "                                 self.n_param_set, 2))\n",
    "\n",
    "        self.y = np.arange(2)\n",
    "\n",
    "        self.hist = []\n",
    "        self.responses = []\n",
    "\n",
    "        # Post <= prior\n",
    "        # shape (n_param_set, )\n",
    "        lp = np.ones(self.n_param_set)\n",
    "        self.log_post = lp - logsumexp(lp)\n",
    "\n",
    "        self.mutual_info = np.zeros(self.n_item)\n",
    "\n",
    "        if teacher_model is not None:\n",
    "            print(teacher_model)\n",
    "            self.teacher = teacher_model(task_param=task_param,\n",
    "                                         **teacher_param)\n",
    "        else:\n",
    "            self.teacher = None\n",
    "\n",
    "        # self.gamma = gamma\n",
    "\n",
    "        self.learner = learner_model(task_param=task_param)\n",
    "\n",
    "        self.true_param = true_param\n",
    "\n",
    "        self.ll_after_pres_full = \\\n",
    "            np.zeros((self.n_item, self.n_param_set, 2))\n",
    "        self.ll_without_pres_full = \\\n",
    "            np.zeros((self.n_item, self.n_param_set, 2))\n",
    "\n",
    "        self.t = 0\n",
    "\n",
    "    def _compute_grid_param(self, grid_size):\n",
    "\n",
    "        return np.asarray(list(\n",
    "            product(*[\n",
    "                np.linspace(\n",
    "                    *self.learner_model.bounds[key],\n",
    "                    grid_size) for key in\n",
    "                sorted(self.learner_model.bounds)])\n",
    "        ))\n",
    "\n",
    "    def _compute_log_lik(self):\n",
    "        for i in range(self.n_item):\n",
    "            self.log_lik[i, :, :] = self._log_p(i)\n",
    "\n",
    "    def _log_p(self, i):\n",
    "\n",
    "        p = self.learner.p_grid(grid_param=self.grid_param, i=i)\n",
    "        log = np.log(p + EPS)\n",
    "        return log\n",
    "\n",
    "    def _update_mutual_info(self):\n",
    "\n",
    "        n_seen = int(np.sum(self.learner.seen))\n",
    "        n_not_seen = self.n_item - n_seen\n",
    "\n",
    "        seen = np.zeros(self.n_item, dtype=bool)\n",
    "        seen[:] = self.learner.seen\n",
    "\n",
    "        not_seen = np.zeros(self.n_item, dtype=bool)\n",
    "        not_seen[:] = np.logical_not(self.learner.seen)\n",
    "\n",
    "        if n_seen == 0:\n",
    "            self._compute_log_lik()\n",
    "            return\n",
    "\n",
    "        n_sample = min(n_seen+1, self.n_item)\n",
    "\n",
    "        log_lik = np.zeros((n_sample, self.n_param_set, 2))\n",
    "\n",
    "        items_seen = self.items[self.learner.seen]\n",
    "\n",
    "        if n_not_seen > 0:\n",
    "            item_not_seen = self.items[not_seen][0]\n",
    "            item_sample = list(items_seen) + [item_not_seen, ]\n",
    "        else:\n",
    "            item_sample = items_seen\n",
    "\n",
    "        for i, item in enumerate(item_sample):\n",
    "            log_lik[i, :, :] = self._log_p(item)\n",
    "\n",
    "        self.log_lik[seen] = log_lik[:n_seen]\n",
    "        if n_not_seen:\n",
    "            self.log_lik[not_seen] = log_lik[-1]\n",
    "\n",
    "        mutual_info = self._mutual_info(\n",
    "            self.log_lik,\n",
    "            self.log_post)\n",
    "\n",
    "        ll_after_pres = np.zeros((n_sample, self.n_param_set, 2))\n",
    "\n",
    "        for i, item in enumerate(item_sample):\n",
    "\n",
    "            for response in (0, 1):\n",
    "                self.learner.update(item=item, response=response)\n",
    "\n",
    "                ll_after_pres[i] += self._log_p(item)\n",
    "\n",
    "                # Unlearn item\n",
    "                self.learner.cancel_update()\n",
    "\n",
    "        ll_without_pres = np.zeros((n_sample, self.n_param_set, 2))\n",
    "\n",
    "        # Go to the future\n",
    "        self.learner.update(item=None, response=None)\n",
    "\n",
    "        for i, item in enumerate(item_sample):\n",
    "            ll_without_pres[i] = self._log_p(item)\n",
    "\n",
    "        # Cancel\n",
    "        self.learner.cancel_update()\n",
    "\n",
    "        self.ll_after_pres_full[seen] = ll_after_pres[:n_seen]\n",
    "\n",
    "        self.ll_without_pres_full[seen] = ll_without_pres[:n_seen]\n",
    "\n",
    "        if n_not_seen:\n",
    "            self.ll_after_pres_full[not_seen] = ll_after_pres[-1]\n",
    "            self.ll_without_pres_full[not_seen] = ll_without_pres[-1]\n",
    "\n",
    "        max_info_next_time_step = np.zeros(self.n_item)\n",
    "\n",
    "        with Pool() as pool:\n",
    "            max_info_next_time_step[:] = \\\n",
    "                pool.map(self._compute_max_info_time_step, self.items)\n",
    "\n",
    "        self.mutual_info[:] = mutual_info + max_info_next_time_step\n",
    "\n",
    "    def _compute_max_info_time_step(self, i):\n",
    "\n",
    "        ll_t_plus_one = np.zeros((self.n_item, self.n_param_set, 2))\n",
    "\n",
    "        ll_t_plus_one[:] = self.ll_without_pres_full[:]\n",
    "        ll_t_plus_one[i] = self.ll_after_pres_full[i]\n",
    "\n",
    "        mutual_info_t_plus_one_given_i = \\\n",
    "            self._mutual_info(ll_t_plus_one,\n",
    "                              self.log_post)\n",
    "\n",
    "        return np.max(mutual_info_t_plus_one_given_i)\n",
    "\n",
    "    # def _update_mutual_info(self):\n",
    "    #\n",
    "    #     for i in range(self.n_item):\n",
    "    #         self.log_lik[i, :, :] = self._log_p(i)\n",
    "    #\n",
    "    #     self.mutual_info[:] = self._mutual_info(self.log_lik,\n",
    "    #                                             self.log_post)\n",
    "    #\n",
    "    #     log_lik_t_plus_one = np.zeros(self.log_lik.shape)\n",
    "    #\n",
    "    #     for i in range(self.n_item):\n",
    "    #\n",
    "    #         # Learn new item\n",
    "    #         self.learner.update(item=i, response=None)\n",
    "    #\n",
    "    #         log_lik_t_plus_one[i, :, :] = self._log_p(i)\n",
    "    #\n",
    "    #         # Unlearn item\n",
    "    #         self.learner.cancel_update()\n",
    "    #\n",
    "    #     mutual_info_t_plus_one_given_i = \\\n",
    "    #         self._mutual_info(log_lik_t_plus_one,\n",
    "    #                           self.log_post)\n",
    "    #\n",
    "    #     self.mutual_info[:] += mutual_info_t_plus_one_given_i\n",
    "\n",
    "    # def _update_mutual_info(self):\n",
    "    #\n",
    "    #     for i in range(self.n_item):\n",
    "    #         self.log_lik[i, :, :] = self._log_p(i)\n",
    "    #\n",
    "    #     self.mutual_info[:] = self._mutual_info(self.log_lik,\n",
    "    #                                             self.log_post)\n",
    "    #\n",
    "    #     mutual_info = self.mutual_info.copy()\n",
    "    #\n",
    "    #     for i in range(self.n_item):\n",
    "    #\n",
    "    #         # Learn new item\n",
    "    #         self.learner.update(item=i, response=None)\n",
    "    #\n",
    "    #         log_lik_t_plus_one = np.zeros(self.log_lik.shape)\n",
    "    #\n",
    "    #         for j in range(self.n_item):\n",
    "    #             log_lik_t_plus_one[j, :, :] = self._log_p(j)\n",
    "    #             # if self.t > 0 and self.learner.seen[j]:\n",
    "    #             # print(f\"t {self.t} i {i} j {j}\")\n",
    "    #\n",
    "    #         mutual_info_t_plus_one_given_i = \\\n",
    "    #             self._mutual_info(log_lik_t_plus_one,\n",
    "    #                               self.log_post)\n",
    "    #\n",
    "    #         print(f\"t {self.t} I t+1 109\", mutual_info_t_plus_one_given_i[109])\n",
    "    #         print(f\"t {self.t} I t+1 i\", mutual_info_t_plus_one_given_i[i])\n",
    "    #         print(f\"t {self.t} I t109 i\", mutual_info[109])\n",
    "    #         print(f\"t {self.t} I t0 i\", mutual_info[i])\n",
    "    #\n",
    "    #         print(f\"i {i}\", self.items[mutual_info_t_plus_one_given_i==np.max(mutual_info_t_plus_one_given_i)])\n",
    "    #         max_info_next_time_step = \\\n",
    "    #             np.max(mutual_info_t_plus_one_given_i)\n",
    "    #\n",
    "    #         self.mutual_info[i] += max_info_next_time_step\n",
    "    #\n",
    "    #         # Unlearn item\n",
    "    #         self.learner.cancel_update()\n",
    "\n",
    "    # def _update_mutual_info_asymmetric(self):\n",
    "    #\n",
    "    #         for i in range(self.n_item):\n",
    "    #             self.log_lik[i, :, :] = self._log_p(i)\n",
    "    #\n",
    "    #         self.mutual_info[:] = self._mutual_info(self.log_lik,\n",
    "    #                                                 self.log_post)\n",
    "    #         # n_best = int(self.gamma*self.n_param_set)\n",
    "    #         # best_param_set_idx = \\\n",
    "    #         #     np.argsort(self.log_post)[-n_best:]\n",
    "    #         print(\"t\", self.t, \"=\" * 10)\n",
    "    #         print(\"mutual info t only\", self.mutual_info)\n",
    "    #\n",
    "    #         for i in range(self.n_item):\n",
    "    #\n",
    "    #             self.learner.set_param(self.post_mean)\n",
    "    #             p_success = self.learner.p(i)\n",
    "    #\n",
    "    #             mutual_info_t_plus_one_for_seq_i_j = np.zeros((2, self.n_item))\n",
    "    #\n",
    "    #             for response in (0, 1):\n",
    "    #                 # Learn new item\n",
    "    #                 self.learner.update(item=i, response=response)\n",
    "    #\n",
    "    #                 log_lik_t_plus_one = np.zeros((\n",
    "    #                     self.n_item,\n",
    "    #                     self.n_param_set,  # n_best,\n",
    "    #                     2))\n",
    "    #\n",
    "    #                 for j in range(self.n_item):\n",
    "    #                     log_lik_t_plus_one[j, :, :] = self._log_p(j)\n",
    "    #\n",
    "    #                 mutual_info_t_plus_one_for_seq_i_j[response] = \\\n",
    "    #                     self._mutual_info(log_lik_t_plus_one,\n",
    "    #                                       self.log_post)\n",
    "    #                 # self.log_post[best_param_set_idx])\n",
    "    #\n",
    "    #                 # Unlearn item\n",
    "    #                 self.learner.cancel_update()\n",
    "    #\n",
    "    #             max_info_next_time_step = \\\n",
    "    #                 np.max(\n",
    "    #                     mutual_info_t_plus_one_for_seq_i_j[0]*(1-p_success)\n",
    "    #                     + mutual_info_t_plus_one_for_seq_i_j[1]*p_success\n",
    "    #                 )\n",
    "    #\n",
    "    #             self.mutual_info[i] += max_info_next_time_step\n",
    "\n",
    "    @staticmethod\n",
    "    def _mutual_info(ll, lp):\n",
    "\n",
    "        lp_reshaped = lp.reshape((1, len(lp), 1))\n",
    "\n",
    "        # ll => likelihood\n",
    "        # shape (n_item, n_param_set, num_responses, )\n",
    "\n",
    "        # Calculate the marginal log likelihood.\n",
    "        # shape (n_item, num_responses, )\n",
    "        mll = logsumexp(ll + lp_reshaped, axis=1)\n",
    "\n",
    "        # Calculate the marginal entropy and conditional entropy.\n",
    "        # shape (n_item,)\n",
    "        ent_mrg = - np.sum(np.exp(mll) * mll, -1)\n",
    "\n",
    "        # Compute entropy obs -------------------------\n",
    "\n",
    "        # shape (n_item, n_param_set, num_responses, )\n",
    "        # shape (n_item, n_param_set, )\n",
    "        ent_obs = - np.multiply(np.exp(ll), ll).sum(-1)\n",
    "\n",
    "        # Compute conditional entropy -----------------\n",
    "\n",
    "        # shape (n_item,)\n",
    "        ent_cond = np.sum(np.exp(lp) * ent_obs, axis=1)\n",
    "\n",
    "        # Calculate the mutual information. -----------\n",
    "        # shape (n_item,)\n",
    "        mutual_info = ent_mrg - ent_cond\n",
    "\n",
    "        return mutual_info\n",
    "\n",
    "    @property\n",
    "    def post(self) -> np.ndarray:\n",
    "        \"\"\"Posterior distributions of joint parameter space\"\"\"\n",
    "        return np.exp(self.log_post)\n",
    "\n",
    "    @property\n",
    "    def post_mean(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        A vector of estimated means for the posterior distribution.\n",
    "        Its length is ``n_param_set``.\n",
    "        \"\"\"\n",
    "        return np.dot(self.post, self.grid_param)\n",
    "\n",
    "    @property\n",
    "    def post_cov(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        An estimated covariance matrix for the posterior distribution.\n",
    "        Its shape is ``(num_grids, n_param_set)``.\n",
    "        \"\"\"\n",
    "        # shape: (N_grids, N_param)\n",
    "        d = self.grid_param - self.post_mean\n",
    "        return np.dot(d.T, d * self.post.reshape(-1, 1))\n",
    "\n",
    "    @property\n",
    "    def post_sd(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        A vector of estimated standard deviations for the posterior\n",
    "        distribution. Its length is ``n_param_set``.\n",
    "        \"\"\"\n",
    "        return np.sqrt(np.diag(self.post_cov))\n",
    "\n",
    "    def update(self, item, response):\n",
    "        r\"\"\"\n",
    "        Update the posterior :math:`p(\\theta | y_\\text{obs}(t), d^*)` for\n",
    "        all discretized values of :math:`\\theta`.\n",
    "\n",
    "        .. math::\n",
    "            p(\\theta | y_\\text{obs}(t), d^*) =\n",
    "                \\frac{ p( y_\\text{obs}(t) | \\theta, d^*) p_t(\\theta) }\n",
    "                    { p( y_\\text{obs}(t) | d^* ) }\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        item\n",
    "            integer (0...N-1)\n",
    "        response\n",
    "            0 or 1\n",
    "        \"\"\"\n",
    "\n",
    "        self.log_post += self.log_lik[item, :, int(response)].flatten()\n",
    "        self.log_post -= logsumexp(self.log_post)\n",
    "\n",
    "        self.learner.update(item, response)\n",
    "        self.teacher.update(item, response)\n",
    "\n",
    "    def get_item(self):\n",
    "\n",
    "        if self.true_param is None:\n",
    "\n",
    "            if np.max(self.post_sd) > self.teacher.confidence_threshold:\n",
    "\n",
    "                self._update_mutual_info()\n",
    "                item = np.random.choice(\n",
    "                    self.items[self.mutual_info == np.max(self.mutual_info)]\n",
    "                )\n",
    "                print(f'{self.t} - selected item {item}' + \"=\"*10)\n",
    "                self.t += 1\n",
    "                return item\n",
    "\n",
    "            else:\n",
    "\n",
    "                self._compute_log_lik()\n",
    "                return self.teacher.ask(\n",
    "                    best_param=self.post_mean)\n",
    "\n",
    "        else:\n",
    "            return self.teacher.ask(best_param=self.true_param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}